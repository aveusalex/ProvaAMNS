{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c700ba69",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets\n",
    "from torchvision.transforms import ToTensor\n",
    "from torch.cuda import device\n",
    "import pandas as pd\n",
    "import torchaudio\n",
    "import os\n",
    "import re\n",
    "import numpy as np\n",
    "import librosa.display\n",
    "%matplotlib inline\n",
    "import numpy, scipy, matplotlib.pyplot as plt, IPython.display as ipd\n",
    "import librosa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "affcda3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNNNetwork(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        # 4 conv blocks / flatten / linear / softmax\n",
    "        self.conv1 = nn.Sequential(\n",
    "            nn.Conv2d(\n",
    "                in_channels=1,\n",
    "                out_channels=32,\n",
    "                kernel_size=3,\n",
    "                stride=1,\n",
    "                padding=2\n",
    "            ),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2),\n",
    "            nn.Dropout(0.3)\n",
    "        )\n",
    "        self.conv2 = nn.Sequential(\n",
    "            nn.Conv2d(\n",
    "                in_channels=32,\n",
    "                out_channels=64,\n",
    "                kernel_size=5,\n",
    "                stride=1,\n",
    "                padding=2\n",
    "            ),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2),\n",
    "            nn.Dropout(0.3)\n",
    "        )\n",
    "        self.conv3 = nn.Sequential(\n",
    "            nn.Conv2d(\n",
    "                in_channels=64,\n",
    "                out_channels=128,\n",
    "                kernel_size=3,\n",
    "                stride=1,\n",
    "                padding=2\n",
    "            ),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2),\n",
    "            nn.Dropout(0.3)\n",
    "        )\n",
    "        self.conv4 = nn.Sequential(\n",
    "            nn.Conv2d(\n",
    "                in_channels=128,\n",
    "               out_channels=256,\n",
    "                kernel_size=5,\n",
    "                stride=1,\n",
    "                padding=2\n",
    "            ),\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2),\n",
    "            nn.Dropout(0.3)\n",
    "        )\n",
    "    \n",
    "        self.dropout = nn.Dropout()\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.linear = nn.Linear(8192, 7)\n",
    "\n",
    "    def forward(self, input_data):\n",
    "        x = self.conv1(input_data)\n",
    "        x = self.conv2(x)\n",
    "        x = self.conv3(x)\n",
    "        x = self.conv4(x)\n",
    "        x = self.dropout(x)\n",
    "        x = self.flatten(x)\n",
    "        logits = self.linear(x)\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8bcd4ee8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CNNNetwork(\n",
       "  (conv1): Sequential(\n",
       "    (0): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2))\n",
       "    (1): ReLU()\n",
       "    (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (3): Dropout(p=0.3, inplace=False)\n",
       "  )\n",
       "  (conv2): Sequential(\n",
       "    (0): Conv2d(32, 64, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
       "    (1): ReLU()\n",
       "    (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (3): Dropout(p=0.3, inplace=False)\n",
       "  )\n",
       "  (conv3): Sequential(\n",
       "    (0): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2))\n",
       "    (1): ReLU()\n",
       "    (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (3): Dropout(p=0.3, inplace=False)\n",
       "  )\n",
       "  (conv4): Sequential(\n",
       "    (0): Conv2d(128, 256, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
       "    (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (4): Dropout(p=0.3, inplace=False)\n",
       "  )\n",
       "  (dropout): Dropout(p=0.5, inplace=False)\n",
       "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
       "  (linear): Linear(in_features=8192, out_features=7, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cnn = CNNNetwork().to(device)\n",
    "cnn.load_state_dict(torch.load('cnnmelhorprovaamns.pth'))\n",
    "cnn.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "da37184c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entrada:  torch.Size([1, 1, 64000])\n",
      "Saída: torch.Size([1, 1, 64000])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "\n",
    "class Encoder(nn.Module):\n",
    "    def __init__(self, encoded_space_dim):\n",
    "        super().__init__()\n",
    "\n",
    "        # Convolutional layers, 3 layers\n",
    "        self.encoder_cnn = nn.Sequential(\n",
    "            nn.Conv1d(1, 64, 1000, stride=64, padding=0),\n",
    "            nn.ReLU(True),\n",
    "            # nn.Conv1d(8, 16, 100, stride=4, padding=0),\n",
    "            # nn.BatchNorm1d(16),\n",
    "            # nn.ReLU(True),\n",
    "            # nn.Conv1d(16, 32, 50, stride=4, padding=0),\n",
    "            # nn.ReLU(True),\n",
    "            # nn.Conv1d(32, 64, 50, stride=2, padding=0),\n",
    "            # nn.ReLU(True)\n",
    "        )\n",
    "\n",
    "        # Flatten layer\n",
    "        # self.flatten = nn.Flatten(start_dim=1)\n",
    "\n",
    "        # Linear section\n",
    "        # self.encoder_lin = nn.Sequential(\n",
    "        #     nn.Linear(496, encoded_space_dim),\n",
    "        #     nn.ReLU(True),\n",
    "        # )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.encoder_cnn(x)\n",
    "        # print(x.shape)\n",
    "        # x = self.flatten(x)\n",
    "        # print(x.shape)\n",
    "        # x = self.encoder_lin(x)\n",
    "        # print(x.shape)\n",
    "        return x\n",
    "\n",
    "\n",
    "class Decoder(nn.Module):\n",
    "\n",
    "    def __init__(self, encoded_space_dim):\n",
    "        super().__init__()\n",
    "        # self.decoder_lin = nn.Sequential(\n",
    "        #     nn.Linear(encoded_space_dim, 496),\n",
    "        #     nn.ReLU(True)\n",
    "        # )\n",
    "        #\n",
    "        # self.unflatten = nn.Unflatten(dim=1,\n",
    "        #                               unflattened_size=(8, 62))\n",
    "\n",
    "        self.decoder_conv = nn.Sequential(\n",
    "            # nn.ConvTranspose1d(64, 32, 50,\n",
    "            #                    stride=2, padding=0, output_padding=0),\n",
    "            # nn.BatchNorm1d(32),\n",
    "            # nn.ReLU(True),\n",
    "            # nn.ConvTranspose1d(32, 16, 50, stride=4,\n",
    "            #                    padding=0, output_padding=0),\n",
    "            # nn.BatchNorm1d(16),\n",
    "            # nn.ReLU(True),\n",
    "            # nn.ConvTranspose1d(16, 8, 100, stride=4,\n",
    "            #                    padding=0, output_padding=0),\n",
    "            # nn.BatchNorm1d(8),\n",
    "            # nn.ReLU(True),\n",
    "            nn.ConvTranspose1d(64, 1, 1024, stride=64,\n",
    "                               padding=0, output_padding=0),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x = self.decoder_lin(x)\n",
    "        # x = self.unflatten(x)\n",
    "        x = self.decoder_conv(x)\n",
    "        x = torch.tanh(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    from time import time\n",
    "    # em gpu\n",
    "    x = torch.randn(1, 1, 4*16000).cuda()\n",
    "    print(\"Entrada: \", x.shape)\n",
    "    encoder = Encoder(64).cuda()\n",
    "    decoder = Decoder(64).cuda()\n",
    "    x_ = encoder(x)\n",
    "    x_ = decoder(x_)\n",
    "    print(\"Saída:\", x_.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2a674bfc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Encoder(\n",
       "  (encoder_cnn): Sequential(\n",
       "    (0): Conv1d(1, 64, kernel_size=(1000,), stride=(64,))\n",
       "    (1): ReLU(inplace=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Carregando os modelos\n",
    "encoder.load_state_dict(torch.load('encoderRede_basicona_tanh2.pth'))\n",
    "encoder.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c86529a0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Decoder(\n",
       "  (decoder_conv): Sequential(\n",
       "    (0): ConvTranspose1d(64, 1, kernel_size=(1024,), stride=(64,))\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decoder.load_state_dict(torch.load('decoderRede_basicona_tanh2.pth'))\n",
    "decoder.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ba6bd408",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "import torchaudio\n",
    "import torch\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "class DadosAE(Dataset):\n",
    "    def __init__(self,\n",
    "               target_sample_rate):\n",
    "        self.raiz = r\"C:\\Users\\heloi\\OneDrive\\Área de Trabalho\\BIA 6 PERIODO\\ANS\"\n",
    "        self.annotations = pd.read_csv(r\"C:\\Users\\heloi\\OneDrive\\Área de Trabalho\\BIA 6 PERIODO\\ANS\\metadata/testeravdess.csv\")\n",
    "        self.annotations_ruido = pd.read_csv(r\"C:\\Users\\heloi\\OneDrive\\Área de Trabalho\\BIA 6 PERIODO\\ANS\\metadata/testeravdessruidoso.csv\")\n",
    "        self.device = \"cuda\"\n",
    "        self.target_sample_rate = target_sample_rate\n",
    "        self.num_samples = 4 * 16000\n",
    "        self.cache = dict()  # controlamos para ter no máximo 100 amostras no cache\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.annotations_ruido)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        if index in self.cache:\n",
    "            return self.cache[index]\n",
    "        path_ruido, path_limpo = self._get_audio_sample_path(index)\n",
    "\n",
    "        # audio com ruido (X)\n",
    "        signal, sr = torchaudio.load(self.raiz + \"/\" + path_ruido)\n",
    "        signal = signal.to(self.device)\n",
    "        signal = self._resample_if_necessary(signal, sr)\n",
    "        signal = self._mix_down_if_necessary(signal)\n",
    "        signal = self._cut_if_necessary(signal)\n",
    "        signal = self._right_pad_if_necessary(signal)\n",
    "\n",
    "        # audio limpo (y)\n",
    "        signal_limpo, sr_limpo = torchaudio.load(self.raiz + \"/\" + path_limpo)\n",
    "        signal_limpo = signal_limpo.to(self.device)\n",
    "        signal_limpo = self._resample_if_necessary(signal_limpo, sr_limpo)\n",
    "        signal_limpo = self._mix_down_if_necessary(signal_limpo)\n",
    "        signal_limpo = self._cut_if_necessary(signal_limpo)\n",
    "        signal_limpo = self._right_pad_if_necessary(signal_limpo)\n",
    "\n",
    "        if len(self.cache) < 256:\n",
    "            self.cache[index] = (signal, signal_limpo)\n",
    "        else:\n",
    "            self.cache = dict()\n",
    "            self.cache[index] = (signal, signal_limpo)\n",
    "\n",
    "        return signal, signal_limpo\n",
    "\n",
    "    def _cut_if_necessary(self, signal):\n",
    "        if signal.shape[1] > self.num_samples:\n",
    "            signal = signal[:, :self.num_samples]\n",
    "        return signal\n",
    "\n",
    "    def _right_pad_if_necessary(self, signal):\n",
    "        length_signal = signal.shape[1]\n",
    "        if length_signal < self.num_samples:\n",
    "            num_missing_samples = self.num_samples - length_signal\n",
    "            last_dim_padding = (0, num_missing_samples)\n",
    "            signal = torch.nn.functional.pad(signal, last_dim_padding)\n",
    "        return signal\n",
    "\n",
    "    def _resample_if_necessary(self, signal, sr):\n",
    "        if sr != self.target_sample_rate:\n",
    "            resampler = torchaudio.transforms.Resample(sr, self.target_sample_rate)\n",
    "            resampler.to(self.device)\n",
    "            signal = resampler(signal)\n",
    "        return signal\n",
    "\n",
    "    def _mix_down_if_necessary(self, signal):\n",
    "        if signal.shape[0] > 1:\n",
    "            signal = torch.mean(signal, dim=0, keepdim=True)\n",
    "        return signal\n",
    "\n",
    "    def _get_audio_sample_path(self, index):\n",
    "        return self.annotations_ruido.iloc[index, 0], self.annotations.iloc[index, 0]\n",
    "\n",
    "    def _get_audio_sample_label(self, index):\n",
    "        return self.annotations.iloc[index, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2ab2c9d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Classe para criação do dataloader, com ela conseguimos abrir os arquivos de áudio a serem utilizados\n",
    "from torch.utils.data import Dataset\n",
    "class SerDataset (Dataset):\n",
    "\n",
    "    def __init__(self,\n",
    "                 annotations_file,\n",
    "                 transformation,\n",
    "                 target_sample_rate,\n",
    "                 num_samples,device):\n",
    "        self.annotations = pd.read_csv(annotations_file)\n",
    "        self.device = device\n",
    "        self.transformation = transformation.to(self.device)\n",
    "        self.target_sample_rate = target_sample_rate\n",
    "        self.num_samples = num_samples\n",
    "        self.cache = dict()\n",
    "        \n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.annotations)\n",
    "\n",
    "    def __getitem__(self,index):\n",
    "        if index in self.cache:\n",
    "          return self.cache[index]\n",
    "        audio_sample_path = self._get_audio_sample_path(index)\n",
    "        label = self._get_audio_sample_label(index)\n",
    "        signal, sr = torchaudio.load(audio_sample_path)\n",
    "        signal = signal.to(self.device)\n",
    "        signal = self._resample_if_necessary(signal, sr)\n",
    "        signal = self._mix_down_if_necessary(signal)\n",
    "        signal = self._cut_if_necessary(signal)\n",
    "        signal = self._right_pad_if_necessary(signal)\n",
    "        signal = self.transformation(signal)\n",
    "        label_dict = {\"fear\":0, \"disgust\":1, \"happy\":2, \"sad\":3, \"neutral\":4, \"angry\":5, \"surprise\":6}\n",
    "        label2 = label_dict[label]\n",
    "        self.cache[index] = signal, label2\n",
    "        return signal, label2\n",
    "\n",
    "    def _cut_if_necessary(self, signal):\n",
    "        if signal.shape[1] > self.num_samples:\n",
    "            signal = signal[:, :self.num_samples]\n",
    "        return signal\n",
    "\n",
    "    def _right_pad_if_necessary(self, signal):\n",
    "        length_signal = signal.shape[1]\n",
    "        if length_signal < self.num_samples:\n",
    "            num_missing_samples = self.num_samples - length_signal\n",
    "            last_dim_padding = (0, num_missing_samples)\n",
    "            signal = torch.nn.functional.pad(signal, last_dim_padding)\n",
    "        return signal\n",
    "\n",
    "    def _resample_if_necessary(self, signal, sr):\n",
    "        if sr != self.target_sample_rate:\n",
    "            resampler = torchaudio.transforms.Resample(sr, self.target_sample_rate)\n",
    "            resampler.to(self.device)\n",
    "            signal = resampler(signal)\n",
    "        return signal\n",
    "\n",
    "    def _mix_down_if_necessary(self, signal):\n",
    "        if signal.shape[0] > 1:\n",
    "            signal = torch.mean(signal, dim=0, keepdim=True)\n",
    "        return signal\n",
    "\n",
    "    def _get_audio_sample_path(self,index):\n",
    "        return self.annotations.iloc[index,0]\n",
    "    def _get_audio_sample_label(self,index):\n",
    "        return self.annotations.iloc[index,1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a02e1e8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataautoencoder = DadosAE(target_sample_rate=16000)\n",
    "batch_size = 16\n",
    "test_loaderautoencoder = DataLoader(test_dataautoencoder, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7d6d6d7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using cuda\n"
     ]
    }
   ],
   "source": [
    "#Acessando a gpu\n",
    "if torch.cuda.is_available():\n",
    "  device = \"cuda\"\n",
    "else:\n",
    "  device = \"cpu\"\n",
    "print(f\"using {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e1a5c03a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 1144 samples in the dataset.\n"
     ]
    }
   ],
   "source": [
    "#Captando os dados de teste com ruído\n",
    "ANNOTATIONS_FILE = \"metadata/testeravdessruidoso.csv\"\n",
    "SAMPLE_RATE = 16000\n",
    "NUM_SAMPLES = 4*16000\n",
    "\n",
    "mel_spectrogram = torchaudio.transforms.MelSpectrogram(\n",
    "    sample_rate=SAMPLE_RATE,\n",
    "    n_fft=1024,\n",
    "    hop_length=512,\n",
    "    n_mels=64\n",
    ")\n",
    "test_data = SerDataset(ANNOTATIONS_FILE,mel_spectrogram,SAMPLE_RATE,NUM_SAMPLES,device)\n",
    "\n",
    "print(f\"There are {len(test_data)} samples in the dataset.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ea661a1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#criando o dataloader\n",
    "test_loader= DataLoader(dataset = test_data, batch_size = batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ba8cabce",
   "metadata": {},
   "outputs": [],
   "source": [
    "#sessão de teste com ruído\n",
    "\n",
    "#lista para armazenar os y verdadeiros\n",
    "y_truetest = []\n",
    "#lista para armazenar os y preditos\n",
    "y_predtest = []\n",
    "\n",
    "cnn.eval()\n",
    "\n",
    "with torch.no_grad():\n",
    "  for inp_test, label_test in test_loader:\n",
    "                \n",
    "      #alocando o input e a label na GPU\n",
    "      inp_test = inp_test.to(device=device)\n",
    "      label_test = label_test.to(device=device)\n",
    "      \n",
    "      #predição do modelo em cima do input\n",
    "      preds3 = cnn(inp_test)\n",
    "      preds3 = nn.functional.softmax(preds3, dim=1)\n",
    "\n",
    "      #preenchendo as listas referente ao y verdadeiro e y predito\n",
    "      for i in range(len(label_test)):\n",
    "        y_truetest.append(int(label_test[i].item()))\n",
    "        y_predtest.append(int(torch.argmax(preds3[i]).item()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "10c9e282",
   "metadata": {},
   "outputs": [],
   "source": [
    "#lista para armazenar os y preditos\n",
    "y_predtestautoencoder = []\n",
    "\n",
    "cnn.eval()\n",
    "\n",
    "with torch.no_grad():\n",
    "  for input, target in test_loaderautoencoder:\n",
    "    encoded_Data = encoder(input)\n",
    "    decoded_Data = decoder(encoded_Data)\n",
    "    mel_spectrogram = torchaudio.transforms.MelSpectrogram(\n",
    "    n_fft=1024,\n",
    "    hop_length=512,\n",
    "    n_mels=64\n",
    ")\n",
    "    mel_spectrogram.to(device)\n",
    "    signal = mel_spectrogram(decoded_Data)\n",
    "            \n",
    "      \n",
    "    #predição do modelo em cima do input\n",
    "    predsautoencoder = cnn(signal)\n",
    "    predsautoencoder = nn.functional.softmax(predsautoencoder, dim=1)\n",
    "\n",
    "    #preenchendo as listas referente ao y verdadeiro e y predito\n",
    "    for i in range(len(target)):\n",
    "        y_predtestautoencoder.append(int(torch.argmax(predsautoencoder[i]).item()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "df4fa523",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_truetest = torch.tensor(y_truetest)\n",
    "y_predtestautoencoder = torch.tensor(y_predtestautoencoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "03e5b447",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1144])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_predtestautoencoder.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "feb87052",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1144])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_truetest.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d45f3282",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[  0,   0, 124,  25,  21,   6,   0],\n",
       "        [  0,   0, 123,  25,  19,   9,   0],\n",
       "        [  1,   0, 128,  18,  19,  10,   0],\n",
       "        [  0,   1, 121,  24,  21,   9,   0],\n",
       "        [  0,   0,  57,  11,  13,   7,   0],\n",
       "        [  0,   0, 123,  22,  25,   6,   0],\n",
       "        [  0,   0, 126,  16,  29,   5,   0]])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torchmetrics import ConfusionMatrix\n",
    "from sklearn.metrics import ConfusionMatrixDisplay\n",
    "##Vendo os resultados/métricas para o teste com ruído\n",
    "#montando a matriz de confusão\n",
    "confmat = ConfusionMatrix(num_classes=7)\n",
    "confmat(y_predtestautoencoder, y_truetest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "aa06117b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "matrizconfusao = confmat(y_predtestautoencoder,y_truetest)\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=np.array(matrizconfusao))\n",
    "disp.plot()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "14557493",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "        Fear       0.00      0.00      0.00       176\n",
      "     Disgust       0.00      0.00      0.00       176\n",
      "       Happy       0.16      0.73      0.26       176\n",
      "         Sad       0.17      0.14      0.15       176\n",
      "     Neutral       0.09      0.15      0.11        88\n",
      "       Angry       0.12      0.03      0.05       176\n",
      "    Surprise       1.00      0.00      0.00       176\n",
      "\n",
      "    accuracy                           0.15      1144\n",
      "   macro avg       0.22      0.15      0.08      1144\n",
      "weighted avg       0.23      0.15      0.08      1144\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "#{\"fear\":0, \"disgust\":1, \"happy\":2, \"sad\":3, \"neutral\":4, \"angry\":5, \"surprise\":6}\n",
    "target_names = ['Fear', 'Disgust', 'Happy','Sad','Neutral','Angry','Surprise']\n",
    "report = classification_report(np.array(y_truetest),np.array(y_predtestautoencoder),target_names= target_names,zero_division=True)\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5497d58b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
